{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Menpora Dukung Pianis Cilik asal Kendal yang I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10 Festival Unik dari Berbagai Belahan DuniaBe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Merawat Pusaka TionghoaLie kim in. Tjia Gwan S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ziarah Riwayat Foramadiahi dan Kastela“Semanga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Budaya Indonesia Pudar karena Ulah Kita Sendir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Menpora Dukung Pianis Cilik asal Kendal yang I...      0\n",
       "1  10 Festival Unik dari Berbagai Belahan DuniaBe...      0\n",
       "2  Merawat Pusaka TionghoaLie kim in. Tjia Gwan S...      0\n",
       "3  Ziarah Riwayat Foramadiahi dan Kastela“Semanga...      0\n",
       "4  Budaya Indonesia Pudar karena Ulah Kita Sendir...      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baca raw_data yang disimpan di pickle\n",
    "df = pd.read_csv('DataProcess/raw_data.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delNumber(text):\n",
    "    noNum = re.sub(r\"\\d+\", \"\", text)\n",
    "    return noNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delSymbol(text):\n",
    "    symbols = \"!\\\"“”#$%&’'()*+-,./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in symbols:\n",
    "        text = np.char.replace(text, i, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delWhiteSpace(text):\n",
    "    text = re.sub('\\s+',' ',str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(text):\n",
    "    text = np.char.lower(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = nltk.tokenize.word_tokenize(str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemove(text, list_stopwords):\n",
    "    text = [word for word in text if not word in list_stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleansing done, save in cleansing_df.csv\n",
      "Case Folding done, save in casefolding_df.csv\n",
      "Tokenization done, save in tokenization_df.csv\n",
      "Stopwords Removal done, save in stopwords_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Data Cleansing\n",
    "df['text']=df.apply(lambda x: delNumber(x[0]), axis=1)\n",
    "df['text']=df.apply(lambda x: delSymbol(x[0]), axis=1)\n",
    "df['text']=df.apply(lambda x: delWhiteSpace(x[0]), axis=1)\n",
    "df.to_csv (r'D:\\JupyterNotebook\\DataProcess\\cleansing_df.csv', index = False, header=True)\n",
    "print(\"Data Cleansing done, save in cleansing_df.csv\")\n",
    "\n",
    "# Case Folding\n",
    "df['text']=df.apply(lambda x: caseFolding(x[0]), axis=1)\n",
    "df.to_csv (r'D:\\JupyterNotebook\\DataProcess\\casefolding_df.csv', index = False, header=True)\n",
    "print(\"Case Folding done, save in casefolding_df.csv\")\n",
    "\n",
    "# Tokenization\n",
    "df['text']=df.apply(lambda x: tokenize(x[0]), axis=1)\n",
    "df.to_csv (r'D:\\JupyterNotebook\\DataProcess\\tokenization_df.csv', index = False, header=True)\n",
    "print(\"Tokenization done, save in tokenization_df.csv\")\n",
    "\n",
    "# Stopwords Removal\n",
    "list_stopwords = set(stopwords.words('indonesian')) # Set dictionary from library\n",
    "df['text']=df.apply(lambda x: stopwordRemove(x[0],list_stopwords), axis=1)\n",
    "df.to_csv (r'D:\\JupyterNotebook\\DataProcess\\stopwords_df.csv', index = False, header=True)\n",
    "print(\"Stopwords Removal done, save in stopwords_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmingSastrawi(text):\n",
    "    newtext = []\n",
    "    for kata in text:\n",
    "        newtext.append(stemmer.stem(kata))\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steeming\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DataProcess/stopwords_df.csv') \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop1 = 10\n",
    "loop2 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# for data in range(len(df)):\n",
    "#     newData = []\n",
    "#     for kata in df['text'].loc[data]:\n",
    "#         newData.append(stemmer.stem(kata))\n",
    "#     df2['text'].loc[data] = newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
