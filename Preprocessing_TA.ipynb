{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n"
     ]
    }
   ],
   "source": [
    "list_stopwords = set(stopwords.words('indonesian'))\n",
    "print(len(list_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Menpora Dukung Pianis Cilik asal Kendal yang I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10 Festival Unik dari Berbagai Belahan DuniaBe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Merawat Pusaka TionghoaLie kim in. Tjia Gwan S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ziarah Riwayat Foramadiahi dan Kastela“Semanga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Budaya Indonesia Pudar karena Ulah Kita Sendir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Menpora Dukung Pianis Cilik asal Kendal yang I...      0\n",
       "1  10 Festival Unik dari Berbagai Belahan DuniaBe...      0\n",
       "2  Merawat Pusaka TionghoaLie kim in. Tjia Gwan S...      0\n",
       "3  Ziarah Riwayat Foramadiahi dan Kastela“Semanga...      0\n",
       "4  Budaya Indonesia Pudar karena Ulah Kita Sendir...      0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baca raw_data\n",
    "df = pd.read_csv('DataProcess/new_raw_data.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(r'D:\\JupyterNotebook\\DataProcess\\tokenization_df.pkl')\n",
    "df2 = pd.read_pickle(r'D:\\JupyterNotebook\\DataProcess\\cleansing_df.pkl')\n",
    "df1['text'].loc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'].loc[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delNumber(text):\n",
    "    noNum = re.sub(r\"\\d+\", \"\", text)\n",
    "    return noNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delSymbol(text):\n",
    "#     symbols = \"!\\\"“”#$%&’'()*+-,./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    symbols = \"!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    for i in symbols:\n",
    "        text = np.char.replace(text, i, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delWhiteSpace(text):\n",
    "    text = re.sub('\\s+',' ',str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(text):\n",
    "    text = np.char.lower(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = nltk.tokenize.word_tokenize(str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemove(text, list_stopwords):\n",
    "    text = [word for word in text if not word in list_stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleansing done, save in cleansing_df.pkl\n",
      "Case Folding done, save in casefolding_df.pkl\n",
      "Tokenization done, save in tokenization_df.pkl\n",
      "Stopwords Removal done, save in stopwords_nltk_df.pkl\n",
      "Wall time: 5.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data Cleansing\n",
    "df['text']=df.apply(lambda x: delNumber(x[0]), axis=1)\n",
    "df['text']=df.apply(lambda x: delSymbol(x[0]), axis=1)\n",
    "df['text']=df.apply(lambda x: delWhiteSpace(x[0]), axis=1)\n",
    "df.to_pickle('D:\\JupyterNotebook\\DataProcess\\cleansing_df.pkl')\n",
    "print(\"Data Cleansing done, save in cleansing_df.pkl\")\n",
    "\n",
    "# Case Folding\n",
    "df['text']=df.apply(lambda x: caseFolding(x[0]), axis=1)\n",
    "df.to_pickle('D:\\JupyterNotebook\\DataProcess\\casefolding_df.pkl')\n",
    "print(\"Case Folding done, save in casefolding_df.pkl\")\n",
    "\n",
    "# Tokenization\n",
    "df['text']=df.apply(lambda x: tokenize(x[0]), axis=1)\n",
    "df.to_pickle(r'D:\\JupyterNotebook\\DataProcess\\tokenization_df.pkl')\n",
    "print(\"Tokenization done, save in tokenization_df.pkl\")\n",
    "\n",
    "# Stopwords Removal\n",
    "list_stopwords = set(stopwords.words('indonesian')) # Set dictionary from library\n",
    "df['text']=df.apply(lambda x: stopwordRemove(x[0],list_stopwords), axis=1)\n",
    "df.to_pickle('D:\\JupyterNotebook\\DataProcess\\stopwords_nltk_df.pkl')\n",
    "print(\"Stopwords Removal done, save in stopwords_nltk_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun']\n"
     ]
    }
   ],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'D:\\JupyterNotebook\\DataProcess\\tokenization_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_temp = df\n",
    "# merubah array ke dataframe\n",
    "for i in range(len(df)):\n",
    "    df['text'].loc[i] = \" \".join(df['text'].loc[i])\n",
    "\n",
    "# stopword sastrawi\n",
    "for i in range(len(df)):\n",
    "    kalimat = df['text'].loc[i]\n",
    "    stop = stopword.remove(kalimat)\n",
    "    df_temp['text'].loc[i] = stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_pickle('D:\\JupyterNotebook\\DataProcess\\stopwords_sastrawi_df.pkl')\n",
    "print(\"Stopwords Removal done, save in stopwords_sastrawi_df.pkl\")\n",
    "df = df_temp\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming Sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmingSastrawi(text):\n",
    "    newtext = []\n",
    "    for kata in text:\n",
    "        newtext.append(stemmer.stem(kata))\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steeming\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[menpora, dukung, pianis, cilik, asal, kendal,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[festival, unik, berbagai, belahan, duniaberba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[merawat, pusaka, tionghoalie, kim, in, tjia, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[ziarah, riwayat, foramadiahi, kastela, “, sem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[budaya, indonesia, pudar, ulah, sendiribudaya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  [menpora, dukung, pianis, cilik, asal, kendal,...      0\n",
       "1  [festival, unik, berbagai, belahan, duniaberba...      0\n",
       "2  [merawat, pusaka, tionghoalie, kim, in, tjia, ...      0\n",
       "3  [ziarah, riwayat, foramadiahi, kastela, “, sem...      0\n",
       "4  [budaya, indonesia, pudar, ulah, sendiribudaya...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(r'D:\\JupyterNotebook\\DataProcess\\stopwords_sastrawi_df.pkl')\n",
    "df['text']=df.apply(lambda x: tokenize(x[0]), axis=1)\n",
    "dfNew = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0\n",
      "done 1\n",
      "done 2\n",
      "done 3\n",
      "done 4\n",
      "done 5\n",
      "done 6\n",
      "done 7\n",
      "done 8\n",
      "done 9\n",
      "done 10\n",
      "done 11\n",
      "done 12\n",
      "done 13\n",
      "done 14\n",
      "done 15\n",
      "done 16\n",
      "done 17\n",
      "done 18\n",
      "done 19\n",
      "done 20\n",
      "done 21\n",
      "done 22\n",
      "done 23\n",
      "done 24\n",
      "done 25\n",
      "done 26\n",
      "done 27\n",
      "done 28\n",
      "done 29\n",
      "done 30\n",
      "done 31\n",
      "done 32\n",
      "done 33\n",
      "done 34\n",
      "done 35\n",
      "done 36\n",
      "done 37\n",
      "done 38\n",
      "done 39\n",
      "done 40\n",
      "done 41\n",
      "done 42\n",
      "done 43\n",
      "done 44\n",
      "done 45\n",
      "done 46\n",
      "done 47\n",
      "done 48\n",
      "done 49\n",
      "done 50\n",
      "done 51\n",
      "done 52\n",
      "done 53\n",
      "done 54\n",
      "done 55\n",
      "done 56\n",
      "done 57\n",
      "done 58\n",
      "done 59\n",
      "done 60\n",
      "done 61\n",
      "done 62\n",
      "done 63\n",
      "done 64\n",
      "done 65\n",
      "done 66\n",
      "done 67\n",
      "done 68\n",
      "done 69\n",
      "done 70\n",
      "done 71\n",
      "done 72\n",
      "done 73\n",
      "done 74\n",
      "done 75\n",
      "done 76\n",
      "done 77\n",
      "done 78\n",
      "done 79\n",
      "done 80\n",
      "done 81\n",
      "done 82\n",
      "done 83\n",
      "done 84\n",
      "done 85\n",
      "done 86\n",
      "done 87\n",
      "done 88\n",
      "done 89\n",
      "done 90\n",
      "done 91\n",
      "done 92\n",
      "done 93\n",
      "done 94\n",
      "done 95\n",
      "done 96\n",
      "done 97\n",
      "done 98\n",
      "done 99\n",
      "done 100\n",
      "done 101\n",
      "done 102\n",
      "done 103\n",
      "done 104\n",
      "done 105\n",
      "done 106\n",
      "done 107\n",
      "done 108\n",
      "done 109\n",
      "done 110\n",
      "done 111\n",
      "done 112\n",
      "done 113\n",
      "done 114\n",
      "done 115\n",
      "done 116\n",
      "done 117\n",
      "done 118\n",
      "done 119\n",
      "done 120\n",
      "done 121\n",
      "done 122\n",
      "done 123\n",
      "done 124\n",
      "done 125\n",
      "done 126\n",
      "done 127\n",
      "done 128\n",
      "done 129\n",
      "done 130\n",
      "done 131\n",
      "done 132\n",
      "done 133\n",
      "done 134\n",
      "done 135\n",
      "done 136\n",
      "done 137\n",
      "done 138\n",
      "done 139\n",
      "done 140\n",
      "done 141\n",
      "done 142\n",
      "done 143\n",
      "done 144\n",
      "done 145\n",
      "done 146\n",
      "done 147\n",
      "done 148\n",
      "done 149\n",
      "done 150\n",
      "done 151\n",
      "done 152\n",
      "done 153\n",
      "done 154\n",
      "done 155\n",
      "done 156\n",
      "done 157\n",
      "done 158\n",
      "done 159\n",
      "done 160\n",
      "done 161\n",
      "done 162\n",
      "done 163\n",
      "done 164\n",
      "done 165\n",
      "done 166\n",
      "done 167\n",
      "done 168\n",
      "done 169\n",
      "done 170\n",
      "done 171\n",
      "done 172\n",
      "done 173\n",
      "done 174\n",
      "done 175\n",
      "done 176\n",
      "done 177\n",
      "done 178\n",
      "done 179\n",
      "done 180\n",
      "done 181\n",
      "done 182\n",
      "done 183\n",
      "done 184\n",
      "done 185\n",
      "done 186\n",
      "done 187\n",
      "done 188\n",
      "done 189\n",
      "done 190\n",
      "done 191\n",
      "done 192\n",
      "done 193\n",
      "done 194\n",
      "done 195\n",
      "done 196\n",
      "done 197\n",
      "done 198\n",
      "done 199\n",
      "done 200\n",
      "done 201\n",
      "done 202\n",
      "done 203\n",
      "done 204\n",
      "done 205\n",
      "done 206\n",
      "done 207\n",
      "done 208\n",
      "done 209\n",
      "done 210\n",
      "done 211\n",
      "done 212\n",
      "done 213\n",
      "done 214\n",
      "done 215\n",
      "done 216\n",
      "done 217\n",
      "done 218\n",
      "done 219\n",
      "done 220\n",
      "done 221\n",
      "done 222\n",
      "done 223\n",
      "done 224\n",
      "done 225\n",
      "done 226\n",
      "done 227\n",
      "done 228\n",
      "done 229\n",
      "done 230\n",
      "done 231\n",
      "done 232\n",
      "done 233\n",
      "done 234\n",
      "done 235\n",
      "done 236\n",
      "done 237\n",
      "done 238\n",
      "done 239\n",
      "done 240\n",
      "done 241\n",
      "done 242\n",
      "done 243\n",
      "done 244\n",
      "done 245\n",
      "done 246\n",
      "done 247\n",
      "done 248\n",
      "done 249\n",
      "done 250\n",
      "done 251\n",
      "done 252\n",
      "done 253\n",
      "done 254\n",
      "done 255\n",
      "done 256\n",
      "done 257\n",
      "done 258\n",
      "done 259\n",
      "done 260\n",
      "done 261\n",
      "done 262\n",
      "done 263\n",
      "done 264\n",
      "done 265\n",
      "done 266\n",
      "done 267\n",
      "done 268\n",
      "done 269\n",
      "done 270\n",
      "done 271\n",
      "done 272\n",
      "done 273\n",
      "done 274\n",
      "done 275\n",
      "done 276\n",
      "done 277\n",
      "done 278\n",
      "done 279\n",
      "done 280\n",
      "done 281\n",
      "done 282\n",
      "done 283\n",
      "done 284\n",
      "done 285\n",
      "done 286\n",
      "done 287\n",
      "done 288\n",
      "done 289\n",
      "done 290\n",
      "done 291\n",
      "done 292\n",
      "done 293\n",
      "done 294\n",
      "done 295\n",
      "done 296\n",
      "done 297\n",
      "done 298\n",
      "done 299\n",
      "done 300\n",
      "done 301\n",
      "done 302\n",
      "done 303\n",
      "done 304\n",
      "done 305\n",
      "done 306\n",
      "done 307\n",
      "done 308\n",
      "done 309\n",
      "done 310\n",
      "done 311\n",
      "done 312\n",
      "done 313\n",
      "done 314\n",
      "done 315\n",
      "done 316\n",
      "done 317\n",
      "done 318\n",
      "done 319\n",
      "done 320\n",
      "done 321\n",
      "done 322\n",
      "done 323\n",
      "done 324\n",
      "done 325\n",
      "done 326\n",
      "done 327\n",
      "done 328\n",
      "done 329\n",
      "done 330\n",
      "done 331\n",
      "done 332\n",
      "done 333\n",
      "done 334\n",
      "done 335\n",
      "done 336\n",
      "done 337\n",
      "done 338\n",
      "done 339\n",
      "done 340\n",
      "done 341\n",
      "done 342\n",
      "done 343\n",
      "done 344\n",
      "done 345\n",
      "done 346\n",
      "done 347\n",
      "done 348\n",
      "done 349\n",
      "done 350\n",
      "done 351\n",
      "done 352\n",
      "done 353\n",
      "done 354\n",
      "done 355\n",
      "done 356\n",
      "done 357\n",
      "done 358\n",
      "done 359\n",
      "done 360\n",
      "done 361\n",
      "done 362\n",
      "done 363\n",
      "done 364\n",
      "done 365\n",
      "done 366\n",
      "done 367\n",
      "done 368\n",
      "done 369\n",
      "done 370\n",
      "done 371\n",
      "done 372\n",
      "done 373\n",
      "done 374\n",
      "done 375\n",
      "done 376\n",
      "done 377\n",
      "done 378\n",
      "done 379\n",
      "done 380\n",
      "done 381\n",
      "done 382\n",
      "done 383\n",
      "done 384\n",
      "done 385\n",
      "done 386\n",
      "done 387\n",
      "done 388\n",
      "done 389\n",
      "done 390\n",
      "done 391\n",
      "done 392\n",
      "done 393\n",
      "done 394\n",
      "done 395\n",
      "done 396\n",
      "done 397\n",
      "done 398\n",
      "done 399\n",
      "done 400\n",
      "done 401\n",
      "done 402\n",
      "done 403\n",
      "done 404\n",
      "done 405\n",
      "done 406\n",
      "done 407\n",
      "done 408\n",
      "done 409\n",
      "done 410\n",
      "done 411\n",
      "done 412\n",
      "done 413\n",
      "done 414\n",
      "done 415\n",
      "done 416\n",
      "done 417\n",
      "done 418\n",
      "done 419\n",
      "done 420\n",
      "done 421\n",
      "done 422\n",
      "done 423\n",
      "done 424\n",
      "done 425\n",
      "done 426\n",
      "done 427\n",
      "done 428\n",
      "done 429\n",
      "done 430\n",
      "done 431\n",
      "done 432\n",
      "done 433\n",
      "done 434\n",
      "done 435\n",
      "done 436\n",
      "done 437\n",
      "done 438\n",
      "done 439\n",
      "done 440\n",
      "done 441\n",
      "done 442\n",
      "done 443\n",
      "done 444\n",
      "done 445\n",
      "done 446\n",
      "done 447\n",
      "done 448\n",
      "done 449\n",
      "done 450\n",
      "done 451\n",
      "done 452\n",
      "done 453\n",
      "done 454\n",
      "done 455\n",
      "done 456\n",
      "done 457\n",
      "done 458\n",
      "done 459\n",
      "done 460\n",
      "done 461\n",
      "done 462\n",
      "done 463\n",
      "done 464\n",
      "done 465\n",
      "done 466\n",
      "done 467\n",
      "done 468\n",
      "done 469\n",
      "done 470\n",
      "done 471\n",
      "done 472\n",
      "done 473\n",
      "done 474\n",
      "done 475\n",
      "done 476\n",
      "done 477\n",
      "done 478\n",
      "done 479\n",
      "done 480\n",
      "done 481\n",
      "done 482\n",
      "done 483\n",
      "done 484\n",
      "done 485\n",
      "done 486\n",
      "done 487\n",
      "done 488\n",
      "done 489\n",
      "done 490\n",
      "done 491\n",
      "done 492\n",
      "done 493\n",
      "done 494\n",
      "done 495\n",
      "done 496\n",
      "done 497\n",
      "done 498\n",
      "done 499\n",
      "done 500\n",
      "done 501\n",
      "done 502\n",
      "done 503\n",
      "done 504\n",
      "done 505\n",
      "done 506\n",
      "done 507\n",
      "done 508\n",
      "done 509\n",
      "done 510\n",
      "done 511\n",
      "done 512\n",
      "done 513\n",
      "done 514\n",
      "done 515\n",
      "done 516\n",
      "done 517\n",
      "done 518\n",
      "done 519\n",
      "done 520\n",
      "done 521\n",
      "done 522\n",
      "done 523\n",
      "done 524\n",
      "done 525\n",
      "done 526\n",
      "done 527\n",
      "done 528\n",
      "done 529\n",
      "done 530\n",
      "done 531\n",
      "done 532\n",
      "done 533\n",
      "done 534\n",
      "done 535\n",
      "done 536\n",
      "done 537\n",
      "done 538\n",
      "done 539\n",
      "done 540\n",
      "done 541\n",
      "done 542\n",
      "done 543\n",
      "done 544\n",
      "done 545\n",
      "done 546\n",
      "done 547\n",
      "done 548\n",
      "done 549\n",
      "done 550\n",
      "done 551\n",
      "done 552\n",
      "done 553\n",
      "done 554\n",
      "done 555\n",
      "done 556\n",
      "done 557\n",
      "done 558\n",
      "done 559\n",
      "done 560\n",
      "done 561\n",
      "done 562\n",
      "done 563\n",
      "done 564\n",
      "done 565\n",
      "done 566\n",
      "done 567\n",
      "done 568\n",
      "done 569\n",
      "done 570\n",
      "done 571\n",
      "done 572\n",
      "done 573\n",
      "done 574\n",
      "done 575\n",
      "done 576\n",
      "done 577\n",
      "done 578\n",
      "done 579\n",
      "done 580\n",
      "done 581\n",
      "done 582\n",
      "done 583\n",
      "done 584\n",
      "done 585\n",
      "done 586\n",
      "done 587\n",
      "done 588\n",
      "done 589\n",
      "done 590\n",
      "done 591\n",
      "done 592\n",
      "done 593\n",
      "done 594\n",
      "done 595\n",
      "done 596\n",
      "done 597\n",
      "done 598\n",
      "done 599\n",
      "done 600\n",
      "done 601\n",
      "done 602\n",
      "done 603\n",
      "done 604\n",
      "done 605\n",
      "done 606\n",
      "done 607\n",
      "done 608\n",
      "done 609\n",
      "done 610\n",
      "done 611\n",
      "done 612\n",
      "done 613\n",
      "done 614\n",
      "done 615\n",
      "done 616\n",
      "done 617\n",
      "done 618\n",
      "done 619\n",
      "done 620\n",
      "done 621\n",
      "done 622\n",
      "done 623\n",
      "done 624\n",
      "done 625\n",
      "done 626\n",
      "done 627\n",
      "done 628\n",
      "done 629\n",
      "done 630\n",
      "done 631\n",
      "done 632\n",
      "done 633\n",
      "done 634\n",
      "done 635\n",
      "done 636\n",
      "done 637\n",
      "done 638\n",
      "done 639\n",
      "done 640\n",
      "done 641\n",
      "done 642\n",
      "done 643\n",
      "done 644\n",
      "done 645\n",
      "done 646\n",
      "done 647\n",
      "done 648\n",
      "done 649\n",
      "done 650\n",
      "done 651\n",
      "done 652\n",
      "done 653\n",
      "done 654\n",
      "done 655\n",
      "done 656\n",
      "done 657\n",
      "done 658\n",
      "done 659\n",
      "done 660\n",
      "done 661\n",
      "done 662\n",
      "done 663\n",
      "done 664\n",
      "done 665\n",
      "done 666\n",
      "done 667\n",
      "done 668\n",
      "done 669\n",
      "done 670\n",
      "done 671\n",
      "done 672\n",
      "done 673\n",
      "done 674\n",
      "done 675\n",
      "done 676\n",
      "done 677\n",
      "done 678\n",
      "done 679\n",
      "done 680\n",
      "done 681\n",
      "done 682\n",
      "done 683\n",
      "done 684\n",
      "done 685\n",
      "done 686\n",
      "done 687\n",
      "done 688\n",
      "done 689\n",
      "done 690\n",
      "done 691\n",
      "done 692\n",
      "done 693\n",
      "done 694\n",
      "done 695\n",
      "done 696\n",
      "done 697\n",
      "done 698\n",
      "done 699\n",
      "done 700\n",
      "done 701\n",
      "done 702\n",
      "done 703\n",
      "done 704\n",
      "done 705\n",
      "done 706\n",
      "done 707\n",
      "done 708\n",
      "done 709\n",
      "done 710\n",
      "done 711\n",
      "done 712\n",
      "done 713\n",
      "done 714\n",
      "done 715\n",
      "done 716\n",
      "done 717\n",
      "done 718\n",
      "done 719\n",
      "done 720\n",
      "done 721\n",
      "done 722\n",
      "done 723\n",
      "done 724\n",
      "done 725\n",
      "done 726\n",
      "done 727\n",
      "done 728\n",
      "done 729\n",
      "done 730\n",
      "done 731\n",
      "done 732\n",
      "done 733\n",
      "done 734\n",
      "done 735\n",
      "done 736\n",
      "done 737\n",
      "done 738\n",
      "done 739\n",
      "done 740\n",
      "done 741\n",
      "done 742\n",
      "done 743\n",
      "done 744\n",
      "done 745\n",
      "done 746\n",
      "done 747\n",
      "done 748\n",
      "done 749\n",
      "done 750\n",
      "done 751\n",
      "done 752\n",
      "done 753\n",
      "done 754\n",
      "done 755\n",
      "done 756\n",
      "done 757\n",
      "done 758\n",
      "done 759\n",
      "done 760\n",
      "done 761\n",
      "done 762\n",
      "done 763\n",
      "done 764\n",
      "done 765\n",
      "done 766\n",
      "done 767\n",
      "done 768\n",
      "done 769\n",
      "done 770\n",
      "done 771\n",
      "done 772\n",
      "done 773\n",
      "done 774\n",
      "done 775\n",
      "done 776\n",
      "done 777\n",
      "done 778\n",
      "done 779\n",
      "done 780\n",
      "done 781\n",
      "done 782\n",
      "done 783\n",
      "done 784\n",
      "done 785\n",
      "done 786\n",
      "done 787\n",
      "done 788\n",
      "done 789\n",
      "done 790\n",
      "done 791\n",
      "done 792\n",
      "done 793\n",
      "done 794\n",
      "done 795\n",
      "done 796\n",
      "done 797\n",
      "done 798\n",
      "done 799\n",
      "done 800\n",
      "done 801\n",
      "done 802\n",
      "done 803\n",
      "done 804\n",
      "done 805\n",
      "done 806\n",
      "done 807\n",
      "done 808\n",
      "done 809\n",
      "done 810\n",
      "done 811\n",
      "done 812\n",
      "done 813\n",
      "done 814\n",
      "done 815\n",
      "done 816\n",
      "done 817\n",
      "done 818\n",
      "done 819\n",
      "done 820\n",
      "done 821\n",
      "done 822\n",
      "done 823\n",
      "done 824\n",
      "done 825\n",
      "done 826\n",
      "done 827\n",
      "done 828\n",
      "done 829\n",
      "done 830\n",
      "done 831\n",
      "done 832\n",
      "done 833\n",
      "done 834\n",
      "done 835\n",
      "done 836\n",
      "done 837\n",
      "done 838\n",
      "done 839\n",
      "done 840\n",
      "done 841\n",
      "done 842\n",
      "done 843\n",
      "done 844\n",
      "done 845\n",
      "done 846\n",
      "done 847\n",
      "done 848\n",
      "done 849\n",
      "done 850\n",
      "done 851\n",
      "done 852\n",
      "done 853\n",
      "done 854\n",
      "done 855\n",
      "done 856\n",
      "done 857\n",
      "done 858\n",
      "done 859\n",
      "done 860\n",
      "done 861\n",
      "done 862\n",
      "done 863\n",
      "done 864\n",
      "done 865\n",
      "done 866\n",
      "done 867\n",
      "done 868\n",
      "done 869\n",
      "done 870\n",
      "done 871\n",
      "done 872\n",
      "done 873\n",
      "done 874\n",
      "done 875\n",
      "done 876\n",
      "done 877\n",
      "done 878\n",
      "done 879\n",
      "done 880\n",
      "done 881\n",
      "done 882\n",
      "done 883\n",
      "done 884\n",
      "done 885\n",
      "done 886\n",
      "done 887\n",
      "done 888\n",
      "done 889\n",
      "done 890\n",
      "done 891\n",
      "done 892\n",
      "done 893\n",
      "done 894\n",
      "done 895\n",
      "done 896\n",
      "done 897\n",
      "done 898\n",
      "done 899\n",
      "done 900\n",
      "done 901\n",
      "done 902\n",
      "done 903\n",
      "done 904\n",
      "done 905\n",
      "done 906\n",
      "done 907\n",
      "done 908\n",
      "done 909\n",
      "done 910\n",
      "done 911\n",
      "done 912\n",
      "done 913\n",
      "done 914\n",
      "done 915\n",
      "done 916\n",
      "done 917\n",
      "done 918\n",
      "done 919\n",
      "done 920\n",
      "done 921\n",
      "done 922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 923\n",
      "done 924\n",
      "done 925\n",
      "done 926\n",
      "done 927\n",
      "done 928\n",
      "done 929\n",
      "done 930\n",
      "done 931\n",
      "done 932\n",
      "done 933\n",
      "done 934\n",
      "done 935\n",
      "done 936\n",
      "done 937\n",
      "done 938\n",
      "done 939\n",
      "done 940\n",
      "done 941\n",
      "done 942\n",
      "done 943\n",
      "done 944\n",
      "done 945\n",
      "done 946\n",
      "done 947\n",
      "done 948\n",
      "done 949\n",
      "done 950\n",
      "done 951\n",
      "done 952\n",
      "done 953\n",
      "done 954\n",
      "done 955\n",
      "done 956\n",
      "done 957\n",
      "done 958\n",
      "done 959\n",
      "done 960\n",
      "done 961\n",
      "done 962\n",
      "done 963\n",
      "done 964\n",
      "done 965\n",
      "done 966\n",
      "done 967\n",
      "done 968\n",
      "done 969\n",
      "done 970\n",
      "done 971\n",
      "done 972\n",
      "done 973\n",
      "done 974\n",
      "done 975\n",
      "done 976\n",
      "done 977\n",
      "done 978\n",
      "done 979\n",
      "done 980\n",
      "done 981\n",
      "done 982\n",
      "done 983\n",
      "done 984\n",
      "done 985\n",
      "done 986\n",
      "done 987\n",
      "done 988\n",
      "done 989\n",
      "done 990\n",
      "done 991\n",
      "done 992\n",
      "done 993\n",
      "done 994\n",
      "done 995\n",
      "done 996\n",
      "done 997\n",
      "done 998\n",
      "done 999\n",
      "done 1000\n",
      "done 1001\n",
      "done 1002\n",
      "done 1003\n",
      "done 1004\n",
      "done 1005\n",
      "done 1006\n",
      "done 1007\n",
      "done 1008\n",
      "done 1009\n",
      "done 1010\n",
      "done 1011\n",
      "done 1012\n",
      "done 1013\n",
      "done 1014\n",
      "done 1015\n",
      "done 1016\n",
      "done 1017\n",
      "done 1018\n",
      "done 1019\n",
      "done 1020\n",
      "done 1021\n",
      "done 1022\n",
      "done 1023\n",
      "done 1024\n",
      "done 1025\n",
      "done 1026\n",
      "done 1027\n",
      "done 1028\n",
      "done 1029\n",
      "done 1030\n",
      "done 1031\n",
      "done 1032\n",
      "done 1033\n",
      "done 1034\n",
      "done 1035\n",
      "done 1036\n",
      "done 1037\n",
      "done 1038\n",
      "done 1039\n",
      "done 1040\n",
      "done 1041\n",
      "done 1042\n",
      "done 1043\n",
      "done 1044\n",
      "done 1045\n",
      "done 1046\n",
      "done 1047\n",
      "done 1048\n",
      "done 1049\n",
      "done 1050\n",
      "done 1051\n",
      "done 1052\n",
      "done 1053\n",
      "done 1054\n",
      "done 1055\n",
      "done 1056\n",
      "done 1057\n",
      "done 1058\n",
      "done 1059\n",
      "done 1060\n",
      "done 1061\n",
      "done 1062\n",
      "done 1063\n",
      "done 1064\n",
      "done 1065\n",
      "done 1066\n",
      "done 1067\n",
      "done 1068\n",
      "done 1069\n",
      "done 1070\n",
      "done 1071\n",
      "done 1072\n",
      "done 1073\n",
      "done 1074\n",
      "done 1075\n",
      "done 1076\n",
      "done 1077\n",
      "done 1078\n",
      "done 1079\n",
      "done 1080\n",
      "done 1081\n",
      "done 1082\n",
      "done 1083\n",
      "done 1084\n",
      "done 1085\n",
      "done 1086\n",
      "Wall time: 26min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "while(counter < len(df)):\n",
    "    dfNew['text'].loc[counter] = stemmingSastrawi(df.loc[counter, 'text'])\n",
    "    print('done',counter)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[menpora, dukung, pianis, cilik, asal, kendal,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[festival, unik, bagai, bahan, duniaberbagai, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[rawat, pusaka, tionghoalie, kim, in, tjia, gw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[ziarah, riwayat, foramadiahi, kastela, , sema...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[budaya, indonesia, pudar, ulah, sendiribudaya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  [menpora, dukung, pianis, cilik, asal, kendal,...      0\n",
       "1  [festival, unik, bagai, bahan, duniaberbagai, ...      0\n",
       "2  [rawat, pusaka, tionghoalie, kim, in, tjia, gw...      0\n",
       "3  [ziarah, riwayat, foramadiahi, kastela, , sema...      0\n",
       "4  [budaya, indonesia, pudar, ulah, sendiribudaya...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "menpora dukung pianis cilik asal kendal ingin pecahkan rekor dunia inggris menpora imam nahrawi hari kamis siang kemarin menerima pianis cilik jefri setiawan melakukan pemecahan rekor dunia bermain piano mata tertutup inggris menpora bangga dukung sepenuhnya keinginan jefri bisa mengharumkan nama indonesia pentas dunia itu disampaikan menpora jumpa pers loby kantor kemenpora jakarta jefri audiensi sebelumnya menpora menyampaikan harapannya menteri pemuda olahraga memfasilitasi pertemuannya presiden joko widodo mendukungnya jelang keberangkatan inggris menanggapi menpora berjanji segera bersurat presiden joko widodo memenuhi keinginan jefri memfasilitasi transportasi akomodasi jefri acara tersebut “ hari ada banyak anak anak muda berprestasi segala kreativitas kemampuannya dorong sepenuhnya terus berprestasi dukungan pemerintah semua pihak termasuk swastalah akan mampu membuat prestasi terdengar gaungnya masyarakat `` jelas imam menpora pesannya jefri mengatakan kemampuan dimiliki jefri harus dikembangkan terus potensi budaya ada indonesia indonesia memiliki banyak seni tari musik lukis `` terus mencari inovasi baru bermusik memadukan seni budaya dimiliki akan mampu hadirkan potensi keunikan bisa dimunculkan membantu promosi pariwisata indonesia tengah gencar dilakukan pemerintah `` tambahnya kesempatan memecahkan rekor dunia mata tertutup diperoleh jefri berkat catatan rekor ditorehkannya ' museum rekor dunia indonesia memainkan keyboard bernyanyi mata tertutup usianya baru menginjak tahun record holders republic uk bermarkas inggris memainkan lagu mata tertutup selama sjam tanggal april mendatang jefri saat masih duduk bangku kelas v sd ananda universal patebon ini menjadi satu satunya anak sd indonesia diundang tampil 'malaysia ke depan akan tampil singapura jepang bermain keyboard bernyanyi mata tertutup penampilan penampilan sebelumnya jefri juga kerap memadukan permainan pianonya seni tari jaipong ulin usik debus seni lukis tari umbul tattoo body painting monolog pertunjukan teater atraksi ular atraksi jaja stone membatik ayah jefry setiawan joko manis terus mensupport mendukung langkah anaknya bisa mengharumkan kendal indonesia kancah dunia internasional terutama bidang musik seusianya “ sebagai orangtua mendukung apapun akan dilakukan jefry bahkan kerap mendampingi saat main sejumlah daerah indonesia maupun malaysia timor lleste beberapa bulan lalu kata joko manis\n"
     ]
    }
   ],
   "source": [
    "df0a = pd.read_pickle(r'D:\\JupyterNotebook\\DataProcess\\stopwords_sastrawi_df.pkl')\n",
    "print(df0a['text'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['menpora', 'dukung', 'pianis', 'cilik', 'asal', 'kendal', 'ingin', 'pecah', 'rekor', 'dunia', 'inggris', 'menpora', 'imam', 'nahrawi', 'hari', 'kamis', 'siang', 'kemarin', 'terima', 'pianis', 'cilik', 'jefri', 'setiawan', 'laku', 'pecah', 'rekor', 'dunia', 'main', 'piano', 'mata', 'tutup', 'inggris', 'menpora', 'bangga', 'dukung', 'sepenuh', 'ingin', 'jefri', 'bisa', 'harum', 'nama', 'indonesia', 'pentas', 'dunia', 'itu', 'sampai', 'menpora', 'jumpa', 'pers', 'loby', 'kantor', 'kemenpora', 'jakarta', 'jefri', 'audiensi', 'belum', 'menpora', 'sampai', 'harap', 'menteri', 'pemuda', 'olahraga', 'fasilitas', 'temu', 'presiden', 'joko', 'widodo', 'dukung', 'jelang', 'berangkat', 'inggris', 'tanggap', 'menpora', 'janji', 'segera', 'surat', 'presiden', 'joko', 'widodo', 'penuh', 'ingin', 'jefri', 'fasilitas', 'transportasi', 'akomodasi', 'jefri', 'acara', 'sebut', '', 'hari', 'ada', 'banyak', 'anak', 'anak', 'muda', 'prestasi', 'segala', 'kreativitas', 'mampu', 'dorong', 'sepenuh', 'terus', 'prestasi', 'dukung', 'perintah', 'semua', 'pihak', 'masuk', 'swasta', 'akan', 'mampu', 'buat', 'prestasi', 'dengar', 'gaung', 'masyarakat', '', 'jelas', 'imam', 'menpora', 'pesan', 'jefri', 'kata', 'mampu', 'milik', 'jefri', 'harus', 'kembang', 'terus', 'potensi', 'budaya', 'ada', 'indonesia', 'indonesia', 'milik', 'banyak', 'seni', 'tari', 'musik', 'lukis', '', 'terus', 'cari', 'inovasi', 'baru', 'musik', 'madu', 'seni', 'budaya', 'milik', 'akan', 'mampu', 'hadir', 'potensi', 'uni', 'bisa', 'muncul', 'bantu', 'promosi', 'pariwisata', 'indonesia', 'tengah', 'gencar', 'laku', 'perintah', '', 'tambah', 'sempat', 'pecah', 'rekor', 'dunia', 'mata', 'tutup', 'oleh', 'jefri', 'berkat', 'catat', 'rekor', 'toreh', '', 'museum', 'rekor', 'dunia', 'indonesia', 'main', 'keyboard', 'nyanyi', 'mata', 'tutup', 'usia', 'baru', 'injak', 'tahun', 'record', 'holders', 'republic', 'uk', 'markas', 'inggris', 'main', 'lagu', 'mata', 'tutup', 'lama', 'sjam', 'tanggal', 'april', 'datang', 'jefri', 'saat', 'masih', 'duduk', 'bangku', 'kelas', 'v', 'sd', 'ananda', 'universal', 'patebon', 'ini', 'jadi', 'satu', 'satu', 'anak', 'sd', 'indonesia', 'undang', 'tampil', 'malaysia', 'ke', 'depan', 'akan', 'tampil', 'singapura', 'jepang', 'main', 'keyboard', 'nyanyi', 'mata', 'tutup', 'tampil', 'tampil', 'belum', 'jefri', 'juga', 'kerap', 'madu', 'main', 'piano', 'seni', 'tari', 'jaipong', 'ulin', 'usik', 'debus', 'seni', 'lukis', 'tari', 'umbul', 'tattoo', 'body', 'painting', 'monolog', 'tunjuk', 'teater', 'atraksi', 'ular', 'atraksi', 'jaja', 'stone', 'batik', 'ayah', 'jefry', 'setiawan', 'joko', 'manis', 'terus', 'mensupport', 'dukung', 'langkah', 'anak', 'bisa', 'harum', 'kendal', 'indonesia', 'kancah', 'dunia', 'internasional', 'utama', 'bidang', 'musik', 'usia', '', 'bagai', 'orangtua', 'dukung', 'apa', 'akan', 'laku', 'jefry', 'bahkan', 'kerap', 'damping', 'saat', 'main', 'jumlah', 'daerah', 'indonesia', 'maupun', 'malaysia', 'timor', 'lleste', 'beberapa', 'bulan', 'lalu', 'kata', 'joko', 'manis']\n"
     ]
    }
   ],
   "source": [
    "print(dfNew['text'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming done, save in stemming_SWsastrawi.pkl\n"
     ]
    }
   ],
   "source": [
    "dfNew.to_pickle('D:\\JupyterNotebook\\DataProcess\\stemming_SWsastrawi.pkl')\n",
    "print(\"Stemming done, save in stemming_SWsastrawi.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Re-arrange position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agar seimbang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat rearrange posisi\n",
    "dfX = pd.read_pickle(r'D:\\JupyterNotebook\\DataProcess\\stemming_SWsastrawi.pkl')\n",
    "# dfX['text']=dfX.apply(lambda x: tokenize(x[0]), axis=1)\n",
    "dfX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfNew\n",
    "# dfX = df0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     94\n",
       "6     91\n",
       "5     91\n",
       "2     91\n",
       "11    90\n",
       "10    90\n",
       "9     90\n",
       "8     90\n",
       "4     90\n",
       "3     90\n",
       "1     90\n",
       "0     90\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_by_label = dict(iter(dfX.groupby('label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dict_by_label)):\n",
    "    dict_by_label[i].reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_by_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>menpora dukung pianis cilik asal kendal ingin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>festival unik berbagai belahan duniaberbagai n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>merawat pusaka tionghoalie kim in tjia gwan so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ziarah riwayat foramadiahi kastela “ semangat ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>budaya indonesia pudar ulah sendiribudayawan n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  menpora dukung pianis cilik asal kendal ingin ...      0\n",
       "1  festival unik berbagai belahan duniaberbagai n...      0\n",
       "2  merawat pusaka tionghoalie kim in tjia gwan so...      0\n",
       "3  ziarah riwayat foramadiahi kastela “ semangat ...      0\n",
       "4  budaya indonesia pudar ulah sendiribudayawan n...      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_by_label[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Algo re-arrange data sehingga tercampur dengan urutan label 0-1-2-3-4-5-6-7-8-9-10-11\n",
    "final_df = pd.DataFrame(columns=['text','label'])\n",
    "counter = 0\n",
    "# Counter sebanyak 30 dataset perlabel\n",
    "while (counter<=89):\n",
    "    temp_final = pd.DataFrame(columns=['text','label'])\n",
    "    for i in range(len(dict_by_label)):\n",
    "        temp_text = dict_by_label[i].text[counter]\n",
    "        temp_label = dict_by_label[i].label[counter]\n",
    "        data_temp = pd.DataFrame({'text':[temp_text],'label':temp_label}, columns=['text','label'])\n",
    "        temp_final = pd.concat([temp_final, data_temp], axis=0)\n",
    "    final_df = pd.concat([final_df, temp_final], axis=0)\n",
    "    counter += 1\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>menpora dukung pianis cilik asal kendal ingin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>survei bi inflasi februari persenbank indonesi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vicky shu siapa sih gak mau nikah cepatvicky s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sempat kritis kini pelaku bom panci bandung te...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beberapa jam kabar media sosial riuh beredarny...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>republika co id jakarta program meningkatkan p...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1076</td>\n",
       "      <td>ceo voxpol center research and consulting pang...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1077</td>\n",
       "      <td>– pasangan ganda campuran indonesia praveen jo...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>baru baru dikabarkan melakukan penyegaran tabl...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>sekretaris daerah nataniel d mandacan mengatak...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     menpora dukung pianis cilik asal kendal ingin ...     0\n",
       "1     survei bi inflasi februari persenbank indonesi...     1\n",
       "2     vicky shu siapa sih gak mau nikah cepatvicky s...     2\n",
       "3     sempat kritis kini pelaku bom panci bandung te...     3\n",
       "4     beberapa jam kabar media sosial riuh beredarny...     4\n",
       "...                                                 ...   ...\n",
       "1075  republika co id jakarta program meningkatkan p...     7\n",
       "1076  ceo voxpol center research and consulting pang...     8\n",
       "1077  – pasangan ganda campuran indonesia praveen jo...     9\n",
       "1078  baru baru dikabarkan melakukan penyegaran tabl...    10\n",
       "1079  sekretaris daerah nataniel d mandacan mengatak...    11\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_df)):\n",
    "    final_df['text'].loc[i] = ' '.join(final_df['text'].loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>menpora dukung pianis cilik asal kendal ingin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>survei bi inflasi februari persenbank indonesi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vicky shu siapa sih gak mau nikah cepatvicky s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sempat kritis kini pelaku bom panci bandung te...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>beberapa jam kabar media sosial riuh beredarny...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  menpora dukung pianis cilik asal kendal ingin ...     0\n",
       "1  survei bi inflasi februari persenbank indonesi...     1\n",
       "2  vicky shu siapa sih gak mau nikah cepatvicky s...     2\n",
       "3  sempat kritis kini pelaku bom panci bandung te...     3\n",
       "4  beberapa jam kabar media sosial riuh beredarny...     4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.to_pickle('D:\\JupyterNotebook\\DataProcess\\preprocess_SWsastrawi_nostemming.pkl')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dfx['text'].loc[2]\n",
    "freq_tokens = nltk.FreqDist(tokens)\n",
    "\n",
    "print('Frequency Tokens : \\n') \n",
    "print(freq_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq_tokens = pd.DataFrame.from_dict(freq_tokens, orient='index')\n",
    "df_freq_tokens.columns = ['Frequency']\n",
    "df_freq_tokens.index.name = 'Key'\n",
    "\n",
    "df_freq_tokens.plot(figsize = (10,10),kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
